{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ea9b90-c50f-486d-86d0-81f64dedb9ec",
   "metadata": {},
   "source": [
    "# 앙상블 모형 실습\n",
    "\n",
    "#### reference\n",
    "[참고1](https://velog.io/@changhtun1/ensemble#%EA%B8%B0%EC%B4%88%EB%B6%80%ED%84%B0-%EC%8C%93%EC%95%84%EA%B0%80%EB%8A%94-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-7)  \n",
    "[참고2](https://blog.naver.com/winddori2002/221829427442)  \n",
    "[참고3](https://teddylee777.github.io/machine-learning/ensemble%EA%B8%B0%EB%B2%95%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B4%ED%95%B4%EC%99%80-%EC%A2%85%EB%A5%98-1)  \n",
    "[참고4](https://hyemin-kim.github.io/2020/08/04/S-Python-sklearn4/)\n",
    "\n",
    "**앙상블이란?**\n",
    "- 여러 개의 모델들을 활용하여 더 강력한 성능의 모델을 만드는 기법\n",
    "\n",
    "**앙상블 기법의 종류**\n",
    "- 보팅 (Voting): 투표를 통해 결과 도출\n",
    "- 배깅 (Bagging): 샘플 중복 생성을 통해 결과 도출\n",
    "- 부스팅 (Boosting): 이전 오차를 보완하면서 가중치 부여\n",
    "- 스태킹 (Stacking): 여러 모델을 기반으로 예측된 결과를 통해 meta 모델이 다시 한번 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be594ae1-0e70-437a-8c1f-d43eb4b6177e",
   "metadata": {},
   "source": [
    "---\n",
    "## Voting\n",
    "[voting 참고](https://yganalyst.github.io/ml/ML_chap6-1/#1-1-%EC%A7%81%EC%A0%91-%ED%88%AC%ED%91%9C)  \n",
    "\n",
    "- 투표를 통해 결정하는 방식\n",
    "- 서로 다른 알고리즘이 도출해 낸 결과물에 대하여 최종 투표하는 방식\n",
    "- hard/soft vote로 나뉨\n",
    "    - hard: 결과물에 대한 최종 값을 투표를 통해 결정(다수결)\n",
    "    - soft: 각 레이블의 예측 확률의 평균으로 최종 분류 결정  \n",
    "    cf. 보통 대회에서는 soft vote 방식이 더 합리적이다.\n",
    "    \n",
    "### >> 분류(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529ba866-b14a-40d1-8b35-9450260f12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 로드\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499c69bb-41b8-419c-8635-07e50ebe3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,\n",
    "                                                   random_state=2021,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72bcfe-bb68-4013-855e-be527aeb8bb4",
   "metadata": {},
   "source": [
    "**hard voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6419c85-4c75-4b92-b2ab-5fdaa7e48eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 1.0\n",
      "RandomForestClassifier : 0.9333333333333333\n",
      "SVC : 0.9777777777777777\n",
      "VotingClassifier : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 약한 학습기 구축\n",
    "log_model = LogisticRegression(max_iter= 1000) # Gradient Descent 방식 반복 횟수 1000회\n",
    "rnd_model = RandomForestClassifier()\n",
    "svm_model = SVC()\n",
    "\n",
    "# 앙상블 모델 구축(hard voting)\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('lr',log_model),('rf',rnd_model),('svc',svm_model)], # 3개의 약한 학습기\n",
    "    voting='hard' # 직접 투표(hard voting)\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "voting_model.fit(X_train,y_train)\n",
    "\n",
    "# 모델 비교\n",
    "for model in (log_model, rnd_model, svm_model, voting_model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    print(model.__class__.__name__, \": {}\".format(accuracy_score(y_test, predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eadc9b-563f-4421-86d4-6185b14be172",
   "metadata": {},
   "source": [
    "**soft voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a5de70-0dd2-4deb-be10-79d6907cd4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 1.0\n",
      "RandomForestClassifier : 0.9333333333333333\n",
      "SVC : 0.9777777777777777\n",
      "VotingClassifier : 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# 약한 학습기 구축\n",
    "log_model = LogisticRegression(max_iter= 1000) # Gradient Descent 방식 반복 횟수 1000회\n",
    "rnd_model = RandomForestClassifier()\n",
    "svm_model = SVC(probability=True) # soft 방식을 위해서 probability 옵션 지정 필요\n",
    "\n",
    "# 앙상블 모델 구축(soft voting)\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('lr',log_model),('rf',rnd_model),('svc',svm_model)], # 3개의 약한 학습기\n",
    "    voting='soft' # 간접 투표(soft voting)\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "voting_model.fit(X_train,y_train)\n",
    "\n",
    "# 모델 비교\n",
    "for model in (log_model, rnd_model, svm_model, voting_model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    print(model.__class__.__name__, \": {}\".format(accuracy_score(y_test, predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690569eb-1744-4baa-816e-bee697bf9386",
   "metadata": {},
   "source": [
    "### >> 회귀 (Regression)\n",
    "\n",
    "*voting regression*은 **voting 방식(hard or soft)을 설정하지 않는다.**\n",
    "\n",
    "아래는 보스턴 데이터를 이용한 예시이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a10f234-73b6-4cff-acc4-1987b5abcd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression : 19.831323672063235\n",
      "Ridge : 19.69619983181413\n",
      "Lasso : 30.29379822196717\n",
      "ElasticNet : 27.513171154748665\n",
      "VotingRegressor : 22.319758694392764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# 데이터셋 로드\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,\n",
    "                                                   random_state=1, shuffle=True)\n",
    "\n",
    "# 약한 학습기 구축\n",
    "lng_model = LinearRegression()\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "lasso_model = Lasso()\n",
    "elt_model = ElasticNet()\n",
    "\n",
    "# 앙상블 모델 구축(hard voting)\n",
    "voting_model = VotingRegressor(\n",
    "    estimators= [('linear', lng_model), ('svr', ridge_model), \n",
    "                 ('rfr', lasso_model), ('elt', elt_model)],\n",
    "    weights=[1,2,1,1])\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "# voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "for model in (lng_model, ridge_model, lasso_model, elt_model, voting_model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predcit = model.predict(X_test)\n",
    "    print(model.__class__.__name__, \": {}\".format(mean_squared_error(y_test, predcit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336542f1-e068-4efc-a15f-3e368c4695ca",
   "metadata": {},
   "source": [
    "---\n",
    "아래는 *make_moons* 함수를 이용해서 가상데이터를 만들어 *voting* 방식을 실습한 예시이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670213a3-e7f3-4cf7-a495-b3ef9526c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.864\n",
      "RandomForestClassifier : 0.88\n",
      "SVC : 0.888\n",
      "VotingClassifier : 0.888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 약한 학습기 구축\n",
    "log_clf = LogisticRegression(solver = 'liblinear') # 최적화에 사용할 알고리즘 설정\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10) # 생성할 tree 개수\n",
    "svm_clf = SVC(gamma='auto')\n",
    "\n",
    "# 앙상블 모델 구축\n",
    "voting_clf = VotingClassifier(estimators=[('lr',log_clf),\n",
    "                                         ('rf',rnd_clf),\n",
    "                                         ('svc',svm_clf)],\n",
    "                             voting='hard')\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "# voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, \":\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265c44d-f6d8-45d7-9777-4bc335f56412",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bagging(Bootstrap Aggregating)\n",
    "\n",
    "- 하나의 모델을 다양하게 학습\n",
    "- Bootstrap은 여러 개의 dataset을 중첩 허용하게 하여 샘플링하여 분할하는 방식이며 Aggregating은 집계를 의미\n",
    "> ex. 데이터 셋의 구성이 [1, 2, 3, 4, 5 ]로 되어 있다면,  \n",
    "> - group 1 = [1, 2, 3]  \n",
    "> - group 2 = [1, 3, 4]  \n",
    "> - group 3 = [2, 3, 5]  \n",
    "> 로 구성된다고 말할 수 있다.\n",
    "- 동일 데이터로부터 복원 랜덤 샘플링을 통해 여러 개의 데이터 셋을 만들고 하나의 모델로 각 데이터에 학습(중복을 허용하므로 같은 훈련 샘플이 여러 예측기에 사용될 수 있음)\n",
    "- 분류의 경우 다수결이고, 회귀의 경우는 각 모델 결과의 평균값을 최종값으로 출력\n",
    "\n",
    "**대표 기법**\n",
    "- Bagging\n",
    "- Random Forest(Decision Tree 기반 Bagging 앙상블)\n",
    "\n",
    "## Pasting\n",
    "- 중복을 허용하지 않고 샘플링하는 방식\n",
    "- bootstrap 옵션을 이용해서 설정(True이면 배깅 방식, False이면 페이스팅 방식)\n",
    "\n",
    "아래는 *make_moons* 함수를 이용해서 가상데이터를 만들어 *bagging* 방식을 실습한 예시이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68450fa5-96c2-4d6d-a1f6-1e31f8c26a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier : 0.856\n",
      "BaggingClassifier : 0.912\n"
     ]
    }
   ],
   "source": [
    "# moon dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise = .3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 모델 생성\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "bag_model = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=500, # 앙상블에 사용할 분류기 개수\n",
    "    max_samples=100, # 하나의 예측기에 들어가는 샘플수 설정\n",
    "    bootstrap=True, # True(중복허용, 배깅, default), False(중복허용 X, 페이스팅)\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "for model in (dt_model, bag_model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    print(model.__class__.__name__, ':', accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae603c3b-6615-4907-90c1-24dd7ce76a86",
   "metadata": {},
   "source": [
    "### + oob 평가\n",
    "\n",
    "배깅을 사용하면 어떤 샘플은 여러번 샘플링되고, 어떤 것은 전혀 사용되지 않을 수도 있다.\n",
    "\n",
    "*BaggingClassifier*는 중복을 허용하여 훈련 세트의 크기 만큼 m개의 샘플을 선택하는데, 이는 평균적으로 각 예측기에 훈렴샘플의 **63%** 정도만 샘플링 된다는 것을 의미한다.  \n",
    "여기서 선택되지 않은 훈련 샘플의 나머지 **37%** 정도를 **oob(out-of-bag)샘플**이라고 부른다.\n",
    "\n",
    "핵심은 예측기가 훈련되는 동안 이 **oob샘플**을 사용하지 않으므로 검증 세트나 교차검증을 사용하지 않고 이를 이용해 평가할 수 있다.\n",
    "\n",
    "앙상블의 평가는 각 예측기의 **oob평가**를 평균하여 얻는다.\n",
    "\n",
    "사이킷런에서 *BaggingClassifier*의 *oob_score=Tru*e로 지정하면 훈련을 마치고 **oob평가**를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eb937ad4-da83-4885-9df6-5fe611470f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906666666666667"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_model = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                             n_estimators=500,\n",
    "                             bootstrap=True,\n",
    "                             n_jobs=-1,\n",
    "                             oob_score=True) # oob 평가 수행\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_model.oob_score_   # 500개 결정트리 분류기의 oob점수를 평균한 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488ece6-ff65-428d-aca0-6584752675f3",
   "metadata": {},
   "source": [
    "약 90%의 정확도를 보여준다.  \n",
    "이는 테스트 데이터셋을 사용하지 않고 훈련데이터에서 사용되지 않은 것을 재활용(?)한 것으로, 실제 테스트 데이터셋과 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7c389474-aa2f-481a-9d44-d259efaa3fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = bag_model.predict(X_test)\n",
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df66c537-192e-4a27-b7fa-8449554e5529",
   "metadata": {},
   "source": [
    "실제로 비슷한 정확도를 보여준다.\n",
    "\n",
    "**oob평가**를 통해 얻은 결정 함수의 값(범주에 속할 확률)은 *oob_decision_function_* 에서 확인할 수 있다(예측기가 *predict_proba()* 메서드를 가지므로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae588481-5dc1-4c4d-88f1-363a8cd7266f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36649215, 0.63350785],\n",
       "       [0.35393258, 0.64606742],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07526882, 0.92473118],\n",
       "       [0.40883978, 0.59116022],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.98492462, 0.01507538],\n",
       "       [0.98360656, 0.01639344]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 375(훈련 데이터셋 크기)개 중 10개만 \n",
    "bag_model.oob_decision_function_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc4c18-ac3b-475c-b322-e8ea704dd606",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "[랜덤포레스트 참고1](https://yganalyst.github.io/ml/ML_chap6-3/)  \n",
    "[랜덤포레스트 참고2](https://jhryu1208.github.io/data/2020/11/16/ML_decision_tree_ensemble_random_forest/)  \n",
    "[랜덤포테스트 참고3](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-5-%EB%9E%9C%EB%8D%A4-%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8Random-Forest%EC%99%80-%EC%95%99%EC%83%81%EB%B8%94Ensemble)\n",
    "- Bagging 기법에 Decission Tree 적용한 것과 같음(배깅방법을 사용한 결정트리 앙상블 모델)\n",
    "- 의사결정나무의 모임(n_estimators 옵션으로 개수 설정)\n",
    "- 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 것이 아니라, 무작위로 선택한 특성들 중에서 최선의 특성을 찾는 방식을 채택하여 무작위성을 더 갖음\n",
    "\n",
    "중요 매개변수는 *n_estimators*, *max_features*이고, *max_depth* 같은 사전 가지치기 옵션이 있다.\n",
    "\n",
    "- *n_estimators*는 클수록 좋다.\n",
    "> 왜냐하면 더 많은 트리를 평균하면 과대적합을 줄여 더 안정적인 모델을 만들기 때문이다.\n",
    "하지만 이로 인해 잃는 것도 있는데, 더 많은 트리는 더 많은 메모리와 긴 훈련 시간으로 이어진다.\n",
    "\n",
    "- *max_features*는 각 트리가 얼마나 무작위가 될지를 결정하며,작은 *max_features*는 과대적합을 줄여준다. 하지만, 일반적으로 아래의 기본값을 쓰는 것이 좋은 방법이다.\n",
    "> 분류 : *max_features=sqrt(n_features)*  \n",
    "> 회귀 : *max_features=n_features*\n",
    "\n",
    "*max_features*나 *max_leaf_nodes* 매개변수를 추가하면 가끔 성능이 향상되기도 한다.\n",
    "\n",
    "\n",
    "### 1) ExtraTree\n",
    "- 랜덤포레스트는 각 노드에서 무작위로 특성을 뽑은 다음 최적의 특성과 임계값을 선택한다.\n",
    "- 하지만 엑스트라 트리는 최적의 특성과 임계값을 찾는것 대신, 후보 특성을 사용해 무작위로 분할한 다음에 최상의 분할 선택\n",
    "- 이렇게되면 기본적으로 편향이 많은 랜던포레스트보다 더욱 편향이 심해지지만, 분산을 더욱 낮출 수 있음\n",
    "- 트리 알고리즘에서는 모든 노드에서 최적의 특성과 임계값을 고르는데 시간이 많이 들지만, 엑스트라 트리를 사용하면 훈련과 예측속도가 빠름\n",
    "- 엑스트라 트리는 *ExtraTreesClassifier*를 이용\n",
    "- *RandomForestClassifier*와 *ExtraTreesClassifier* 중 어떤 것이 더 좋을지는 판단하기 어렵기 때문에, 교차검증을 통해서 서로 비교해보고, 더 나은 모델을 선택하여 그리드 탐색방법을 사용해 하이퍼파라미터 튜닝 수행\n",
    "\n",
    "### 2) 특성 중요도\n",
    "- 랜덤포레스트는 성능이 좋다는 장점말고, 특성의 상대적 중요도를 측정하기 쉬움(트리기반 모델은 특성 중요도 제공)\n",
    "- 사이킷런에서는 어떤 특성을 사용한 노드가 평균적으로 불순도를 감소시키는지 확인하여 특성 중요도를 측정하고, 훈련이 끝나고 난 뒤에 특성마다 자동으로 점수를 계산하고 저장\n",
    "- 저장된 값은 *featureimportances* 변수에 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "06176b68-9835-44ad-8464-f4589bb74ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 평가: 1.0\n",
      "평가 데이터 평가: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지 로드\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 데이터셋 로드\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)\n",
    "# 모델 생성 및 학습\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 평가\n",
    "predict = model.predict(X_test)\n",
    "print('학습 데이터 평가: {}'.format(model.score(X_train, y_train)))\n",
    "print('평가 데이터 평가: {}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c94bde7-8baa-4d8f-a8f1-67c2a36667f0",
   "metadata": {},
   "source": [
    "다음 코드는 iris데이터셋에 랜덤포레스트를 훈련시키고 중요도를 출력한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8e5926d-68db-4692-a496-45b7a6fd4bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09471873135932563\n",
      "sepal width (cm) 0.024490913795713644\n",
      "petal length (cm) 0.4408647568319765\n",
      "petal width (cm) 0.4399255980129843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "model = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "model.fit(iris.data, iris.target)\n",
    "for name, score in zip(iris.feature_names, model.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea6c5c-2596-45b4-8de4-fd742f1ca71c",
   "metadata": {},
   "source": [
    "변수는 총 4개이고, 위의 4개 점수를 합하면 1이된다.  \n",
    "즉, 꽃잎의 길이(petal length)와 꽃잎의 너비(petal width)가 각각 45%, 43%로 가장 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639fa18-8980-4849-8f61-f262f6005572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
