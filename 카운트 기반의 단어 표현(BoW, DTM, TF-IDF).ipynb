{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127922ad-6c5f-4713-ae2a-62d92217de02",
   "metadata": {},
   "source": [
    "# 카운트 기반의 단어 표현(BoW, DTM, TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f1f78-47f1-410e-96f6-a95d43296c95",
   "metadata": {},
   "source": [
    "## [Bag of Words](https://wikidocs.net/22650)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958263fc-103b-4a0c-af1b-b673b63bf863",
   "metadata": {},
   "source": [
    "Bag of Words란 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
    "\n",
    "[BoW를 만드는 과정]\n",
    "1. 각 단어에 고유한 정수 인덱스를 부여  # 단어 집합 생성.\n",
    "2. 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만듦."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6965c1-1bd7-405c-b7a8-cf51efbd6164",
   "metadata": {},
   "source": [
    "### step1. CountVectorizer 클래스로 BoW 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f18614-109e-45e0-9bff-f371cb4d9bfe",
   "metadata": {},
   "source": [
    "#### 문서1: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\n",
    "\n",
    "문서1에 대해 BoW를 만든다. 아래의 함수는 입력된 문서에 대해서 단어 집합을 만들어 각 단어에 정수 인덱스를 할당하고, BoW를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ff13a8-6f60-41e2-bafe-a30b7ad7b52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 2 1 2 1]]\n",
      "vocabulary : {'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['you know I want your love. because I love you.']\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도수 기록\n",
    "print('bag of words vector :', vector.fit_transform(corpus).toarray())\n",
    "\n",
    "# 각 단어의 인덱스가 어떻게 부여되었는지 출력\n",
    "print('vocabulary :', vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec5a8f-efd8-48b1-8f5b-3814e7bc30f4",
   "metadata": {},
   "source": [
    "you와 love는 두 번씩 언급되었으므로 각각 인덱스 2와 4에서 2의 값을 가지며, 그 외의 값에서는 1의 값을 갖는다.  \n",
    "또한 알파벳 I는 BoW를 만드는 과정에서 사라졌는데, 이는 CounterVectorizer가 기본적으로 길이가 2 이상인 문자에 대해서만 토큰으로 인식한다.  \n",
    "영어에서는 길이가 짧은 문자를 제거하는 것도 전처리 작업으로 고려된다.\n",
    "\n",
    "주의할 것은 **CountVectorizer는 단지 띄어쓰기만을 기준**으로 단어를 자르는 낮은 수준의 토큰화를 진행하고 BoW를 만든다는 점이다. 따라서 한국어에 적용하면 BoW가 제대로 만들어지지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211036f4-ea87-419e-aa67-a7ebf141b8ed",
   "metadata": {},
   "source": [
    "### step2. 불용어를 제거한 BoW 만들기\n",
    "\n",
    "CountVectorizer는 불용어를 지정하면, 불용어는 제외하고 BoW를 만들 수 있도록 불용어 제거 기능을 지원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffe3c4-804d-48a1-841f-88496e453501",
   "metadata": {},
   "source": [
    "#### (1) 사용자 정의 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31896dd9-1ef5-4188-910a-4e5f55d2b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2526b82c-8938-475d-a056-86d1d8f4f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector:  [[1 1 1 1 1]]\n",
      "vocabulary:  {'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=['the', 'a', 'an', 'is', 'not'])\n",
    "print('bag of words vector: ', vect.fit_transform(text).toarray())\n",
    "print('vocabulary: ', vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40b6af-0e16-4ead-bdb2-74ac86178c41",
   "metadata": {},
   "source": [
    "#### (2) CountVectorizer에서 제공하는 자체 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3735ab33-27a6-47a1-bd79-bd4c2b748134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1]]\n",
      "vocabulary : {'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray())\n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6c720-2ac5-4587-b100-355344b032fa",
   "metadata": {},
   "source": [
    "#### (3) NLTK에서 지원하는 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2da694e3-5e5f-4265-a839-f518a8ca1bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1 1]]\n",
      "vocabulary : {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "stop_words = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words=stop_words)\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray()) \n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76387f-08df-47e9-97ee-af07f4084d40",
   "metadata": {},
   "source": [
    "---\n",
    "## 문서 단어 행렬(Document-Term Matrix, DTM)\n",
    "\n",
    "- 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현\n",
    "- 각 문서에 대한 BoW를 하나의 행렬로 만든 것\n",
    "- BoW 표현을 다수의 문서에 대해서 행렬로 표현하고 부르는 용어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810cbaa-b160-4cea-9768-2e49a49df22d",
   "metadata": {},
   "source": [
    "---\n",
    "## TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "- TF-IDF(Term Frequency-Inverse Document Frequency)는 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정 식을 취함)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법\n",
    "- 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰임\n",
    "- TF-IDF은 TF와 IDF를 곱한 값을 의미\n",
    "    - **모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단하며, 특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단**\n",
    "    - TF-IDF 값이 낮으면 중요도가 낮은 것이며, TF-IDF 값이 크면 중요도가 큰 것\n",
    "\n",
    "tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.\n",
    "\n",
    "df(t) : 특정 단어 t가 등장한 문서의 수.\n",
    "\n",
    "idf(d, t) : df(t)에 반비례하는 수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f51f64c-0a37-46ef-a7f1-e93a2fe4dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### step1. 파이썬으로 TF-IDF 직접 구\n",
    "import pandas as pd # 데이터프레임 사용을 위해\n",
    "from math import log # IDF 계산을 위해\n",
    "\n",
    "docs = [\n",
    "    '먹고 싶은 사과',\n",
    "    '먹고 싶은 바나나',\n",
    "    '길고 노란 바나나 바나나',\n",
    "    '저는 과일이 좋아요'\n",
    "]\n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70262757-7bc7-4ce7-991d-c69e7999d5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52e5076-0106-49e7-bd3e-8047adfbb62f",
   "metadata": {},
   "source": [
    "TF, IDF, 그리고 TF-IDF 값을 구하는 함수를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b41ade87-e0bc-481d-8d66-43425768558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 문서의 수\n",
    "N = len(docs) \n",
    "\n",
    "def tf(t, d):\n",
    "  return d.count(t)\n",
    "\n",
    "def idf(t):\n",
    "  df = 0\n",
    "  for doc in docs:\n",
    "    df += t in doc\n",
    "  return log(N/(df+1))\n",
    "\n",
    "def tfidf(t, d):\n",
    "  return tf(t,d)* idf(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7499f-e096-4d4d-a4e2-83e4c77b8cd3",
   "metadata": {},
   "source": [
    "TF를 구한다. 다시 말해 DTM을 데이터프레임에 저장하여 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18c36ff1-eafa-4257-8c0a-ced865898514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "0    0   0   0   1    0   1   1   0    0\n",
       "1    0   0   0   1    1   0   1   0    0\n",
       "2    0   1   1   0    2   0   0   0    0\n",
       "3    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "# 각 문서에 대해서 아래 연산을 반복\n",
    "for i in range(N):\n",
    "  result.append([])\n",
    "  d = docs[i]\n",
    "  for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result[-1].append(tf(t, d))\n",
    "\n",
    "tf_ = pd.DataFrame(result, columns = vocab)\n",
    "tf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1bf60-c147-4c2c-9cef-0a06ef9f174e",
   "metadata": {},
   "source": [
    "각 단어에 대한 IDF 값을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1caa11af-ffa1-40b2-80e9-8a56628ea080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>과일이</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>길고</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>노란</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>먹고</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>싶은</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저는</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>좋아요</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "과일이  0.693147\n",
       "길고   0.693147\n",
       "노란   0.693147\n",
       "먹고   0.287682\n",
       "바나나  0.287682\n",
       "사과   0.693147\n",
       "싶은   0.287682\n",
       "저는   0.693147\n",
       "좋아요  0.693147"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "    \n",
    "idf_=pd.DataFrame(result, index=vocab, columns=[\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e64a3-426b-49f0-aefd-7dd38ad0ade0",
   "metadata": {},
   "source": [
    "TF-IDF 행렬을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36f8a998-2d2e-4af0-b0a5-9645abfe10fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
       "0  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
       "1  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
       "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
       "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         저는       좋아요  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.693147  0.693147  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "  result.append([])\n",
    "  d = docs[i]\n",
    "  for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result[-1].append(tfidf(t,d))\n",
    "\n",
    "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db5c64-a54d-4855-bfcd-98fa6c37f6b8",
   "metadata": {},
   "source": [
    "### step2. 사이킷런을 이용한 DTM과 TF-IDF 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7f1f45b-8285-4088-bfb7-3e1a01de3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "  'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',  \n",
    "]\n",
    "\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
    "print(vector.fit_transform(corpus).toarray())\n",
    "\n",
    "# 각 단어와 맵핑된 인덱스 출력\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396a774-c3a6-4151-9d68-3c7c12c48991",
   "metadata": {},
   "source": [
    "DTM이 완성됐다. 각 단어의 인덱스가 어떻게 부여되었는지 확인하기 위해 인덱스를 확인해보겠다.  \n",
    "첫 번째 열의 경우에는 0의 인덱스를 가진 do이다. do는 세번째 문서에만 등장했기 때문에, 세번째 행에서만 1의 값을 가진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb527a-a5cc-4290-89bf-a6b18194bb27",
   "metadata": {},
   "source": [
    "사이킷런은 TF-IDF를 자동 계산해주는 TfidfVectorizer를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6792d8d8-d1c1-473a-a698-6da8835baeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "  'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',  \n",
    "]\n",
    "\n",
    "tfidfv = TfidfVectorizer()\n",
    "print(tfidfv.fit_transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39b511-2897-415d-9024-bd65fa69363b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
