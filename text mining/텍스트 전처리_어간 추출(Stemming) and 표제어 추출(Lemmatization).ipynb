{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca622a74-f522-4a33-bada-7786c3565cf6",
   "metadata": {},
   "source": [
    "## 텍스트 전처리_어간 추출(Stemming) and 표제어 추출(Lemmatization)\n",
    "[02-03 어간 추출(Stemming) and 표제어 추출(Lemmatization)](https://wikidocs.net/21707)\n",
    "\n",
    "- 공통점: 하나의 단어로 일반화시킬 수 있다면 하나의 단어로 일반화시켜서 문서 내 단어수를 줄임.\n",
    "    - BoW 표현을 사용하는 자연어 처리 문제에서 주로 사용함\n",
    "    \n",
    "### 1. 표제어 추출(Lemmatization)\n",
    "- am, are, is의 표제어 → **be**\n",
    "- 표제어 추출 방법\n",
    "    - 단어의 **형태학적 파싱**을 먼저 진행\n",
    "    - 형태소: 의미를 가진 가장 작은 단위\n",
    "    - 형태학: 형태소로부터 단어들을 만들어가는 학문\n",
    "    - 형태소 종류: 어간(stem, 단어의 의미를 담고 있는 부분), 접사(affix, 단어에 추가 의미를 주는 부분)\n",
    "    - cats → cat(어간) + -s(접사)\n",
    "    - fox → 독립적인 형태소이므로 분리 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101ec882-1d0e-4a27-90b4-cff8ed2d9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print('표제어 추출 전 :',words)\n",
    "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004986d7-c691-4f9b-a604-15cb268ffbf2",
   "metadata": {},
   "source": [
    "dy나 ha와 같이 의미를 알 수 없는 적절하지 못한 단어를 출력하고 있음.  \n",
    "이는 표제어 추출기(lemmatizer)가 본래 단어의 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76257afb-5686-485a-8a57-bd989cfa4181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('dies', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88730c6c-8cb5-4ea9-8cd9-88ad9a04e204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('watched', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f326f2-fa1d-42e7-a77e-d1fb510df108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('has', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083cad92-11e7-4551-a4a7-307594dff42b",
   "metadata": {},
   "source": [
    "### 2. 어간 추출(Stemming)\n",
    "- 어간(Stem)을 추출하는 작업을 의미함.\n",
    "- 형태학적 분석을 단순화한 버전이라 볼 수 있음.\n",
    "- 섬세한 작업이 아니라 어간 추출 후에 나오는 단어는 사전에 존재하지 않을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dfc540-c1f1-4f9a-a90b-9f77d89e8bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
      "어간 추출 후 : ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "sentence = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
    "tokenized_sentence = word_tokenize(sentence)\n",
    "\n",
    "print('어간 추출 전 :', tokenized_sentence)\n",
    "print('어간 추출 후 :',[stemmer.stem(word) for word in tokenized_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2910939-31bd-47c4-b157-cc5dc07f1a90",
   "metadata": {},
   "source": [
    "포터 알고리즘의 어간 추출은 아래 규칙들을 가짐.\n",
    "\n",
    "ALIZE → AL  \n",
    "ANCE → 제거  \n",
    "ICAL → IC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2dfb070-a8f8-4680-9fcb-554ad3a8f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['formalize', 'allowance', 'electricical']\n",
      "어간 추출 후: ['formal', 'allow', 'electric']\n"
     ]
    }
   ],
   "source": [
    "words = ['formalize', 'allowance', 'electricical']\n",
    "\n",
    "print('어간 추출 전 :', words)\n",
    "print('어간 추출 후:', [stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23d4d5-f853-47d1-a5c3-b3f946c47ab0",
   "metadata": {},
   "source": [
    "어간 추출 속도는 표제어 추출보다 일반적으로 빠른데, 포터 어간 추출기는 정밀하게 설계되어 정확도가 높으므로 영어 자연어 처리에서 어간 추출을 하고자 한다면 가장 준수한 선택임.  \n",
    "NLTK에서는 포터 알고리즘 외에도 랭커스터 스태머(Lancaster Stemmer) 알고리즘을 지원함.  \n",
    "이번에는 포터 알고리즘과 랭커스터 스태머 알고리즘으로 각각 어간 추출을 진행했을 때, 이 둘의 결과를 비교함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ddd04c-f6fe-4193-ae55-08a6c8c3d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "포터 스테머의 어간 추출 후 : ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
      "랭커스터 스테머의 어간 추출 후 : ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print('어간 추출 전 :', words)\n",
    "print('포터 스테머의 어간 추출 후 :', [porter_stemmer.stem(w) for w in words])\n",
    "print('랭커스터 스테머의 어간 추출 후 :', [lancaster_stemmer.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b28a0-10b1-4755-9201-541cb42aeab4",
   "metadata": {},
   "source": [
    "### 3. 한국에서의 어간 추출\n",
    "- **용언**에 해당되는 '동사', '형용사'는 어간(stem)과 어미(ending)의 결합으로 구성됨.\n",
    "\n",
    "1. 활용(conjugation)\n",
    "- 용언의 어간(stem)이 어미(ending)를 가지는 일을 의미함.\n",
    "    - **어간(stem)**: 용언(동사, 형용사)을 활용할 때, 원칙적으로 모양이 변하지 않는 부분. 활용에서 어미에 선행하는 부분. 때론 어간의 모양도 바뀔 수 있음(예: 긋다, 긋고, 그어서, 그어라).\n",
    "    - **어미(ending)**: 용언의 어간 뒤에 붙어서 활용하면서 변하는 부분이며, 여러 문법적 기능을 수행\n",
    "\n",
    "2. 규칙 활용\n",
    "- 규칙 활용은 어간이 어미를 취할 떄, 어간의 모습이 일정함.\n",
    "    - 잡(어간) + 다(어미)\n",
    "    - 위처럼 규칙 기반으로 어미를 단순히 분리해주면 어간 추출이 됨.\n",
    "\n",
    "3. 불규칙 활용\n",
    "- 어간이 어미를 취할 때 어간의 모습이 바뀌거나 취하는 어미가 특수한 어미일 경우를 말함.\n",
    "- 예를 들어 ‘듣-, 돕-, 곱-, 잇-, 오르-, 노랗-’ 등이 ‘듣/들-, 돕/도우-, 곱/고우-, 잇/이-, 올/올-, 노랗/노라-’와 같이 어간의 형식이 달라지는 일이 있거나 ‘오르+ 아/어→올라, 하+아/어→하여, 이르+아/어→이르러, 푸르+아/어→푸르러’와 같이 일반적인 어미가 아닌 특수한 어미를 취하는 경우 불규칙활용을 하는 예에 속함.\n",
    "- 이 경우에는 좀 더 복잡한 규칙을 필요로 함.\n",
    "- [참고 링크](https://namu.wiki/w/%ED%95%9C%EA%B5%AD%EC%96%B4/%EB%B6%88%EA%B7%9C%EC%B9%99%20%ED%99%9C%EC%9A%A9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1512d-10a5-4f45-a9d9-56e34010afb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
