{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81be80f-fe1c-4ae9-84d1-24a0a12cc8e8",
   "metadata": {},
   "source": [
    "## 텍스트 전처리_정제(Cleaning) and 정규화(Normalization)\n",
    "[02-02 정제(Cleaning) and 정규화(Normalization)](https://wikidocs.net/21693)\n",
    "\n",
    "- 토큰화 작업 전, 후에는 텍스트 데이터를 용도에 맞게 정제(cleaning) 및 정규화(normalization)하는 일이 항상 함께 진행함.\n",
    "- 정제(cleaning) : 갖고 있는 코퍼스로부터 노이즈 데이터를 제거한다.\n",
    "- 정규화(normalization) : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어준다.\n",
    "\n",
    "### 1. 규칙에 기반한 표기가 다른 단어들의 통합\n",
    "- USA, US → 하나로 통일\n",
    "- uh-huh, uhhuh → 하나로 통일\n",
    "- 표기가 다른 단어들을 통합하는 방법인 어간 추출(stemming)과 표제어 추출(lemmatizaiton) 방법도 존재함.\n",
    "\n",
    "### 2. 대소문자 통합\n",
    "- 소문자로 변환하는 것이 유용하지만 고유명사(US, 회사 및 사람 이름 등)은 그대로 유지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cdeb4-ce0b-4f20-ba4b-2950c1eb2666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
